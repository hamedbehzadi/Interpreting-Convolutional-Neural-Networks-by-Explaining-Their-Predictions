# Interpreting-Convolutional-Neural-Networks-by-Explaining-Their-Predictions
# Abstract
We propose a method that exploits the feedback provided by visual explanation methods combined with pattern mining techniques to identify the relevant class-specific and class-shared internal units. In addition, we put forward a patch extraction approach to find faithfully class-specific and class-shared visual patterns. Contrary to the common practice in literature, our approach does not require pushing augmented visual patches through the model. Experiments on two CNN architectures show the effectiveness of the proposed method.


## Description of the proposed interpretation pipline
Proposed Interpretation method. (1) Visual explanations are generated by an explanation method, followed by (2) extraction of patches showing highlighted parts. (3) A transaction dataset is created via the patches. Finally, a pattern mining algorithm (4-6) extracts class-specific and class-shared convolutional filters and their corresponding visual patches. This serves as a means for model interpretation.

![Revised_teaser_figure drawio](https://github.com/hamedbehzadi/Interpreting-Convolutional-Neural-Networks-by-Explaining-Their-Predictions/assets/45251957/4c22e848-18ed-4df6-a85e-bb3ad476425e)
